{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'default_rng'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ceffa43f6475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#from gensim.test.utils import common_texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#from collections import Counter #like map but worse cuz it senses only the tally --> not for computation :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from .preprocessing import (  # noqa:F401\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpreprocess_documents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpreprocess_string\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#: A default, shared numpy-Generator-based PRNG for any/all uses that don't require seeding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mdefault_prng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'default_rng'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import gc\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import nltk as nlp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "#from gensim.test.utils import common_texts\n",
    "#from collections import Counter #like map but worse cuz it senses only the tally --> not for computation :(\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17051795235338798196\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2907098318\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17411982008057118797\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOADING IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(r'..\\\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['sentiment'] = dataframe['sentiment'].replace('positive', 1)\n",
    "dataframe['sentiment'] = dataframe['sentiment'].replace('negative', 0)\n",
    "dataframe.head()\n",
    "#in case of non-binary classes it makes more sense to use label encoder rather than replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK FOR NULLS AND DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop_duplicates(subset='review', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split into test and train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataframe, test_size = 0.3, random_state = 156, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>This movie is about a group of people who are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20811</th>\n",
       "      <td>This was a less than exciting short film I saw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49519</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Crackerjack, starring Mick Malloy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32422</th>\n",
       "      <td>Why do I watch movies like this ? - other than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49066</th>\n",
       "      <td>\"Why did they make them so big? Why didn't the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "3298   This movie is about a group of people who are ...          0\n",
       "20811  This was a less than exciting short film I saw...          0\n",
       "49519  <br /><br />Crackerjack, starring Mick Malloy ...          1\n",
       "32422  Why do I watch movies like this ? - other than...          0\n",
       "49066  \"Why did they make them so big? Why didn't the...          1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>Chaplin was great a silent comedian, but many ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>This has got to be one of Australia's best pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31604</th>\n",
       "      <td>A surprising misfire from the usually reliable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26404</th>\n",
       "      <td>Why do people bitch about this movie and not a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30664</th>\n",
       "      <td>Criticism of the film EVENING, based on the no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "10310  Chaplin was great a silent comedian, but many ...          0\n",
       "20472  This has got to be one of Australia's best pro...          1\n",
       "31604  A surprising misfire from the usually reliable...          0\n",
       "26404  Why do people bitch about this movie and not a...          1\n",
       "30664  Criticism of the film EVENING, based on the no...          1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review'].values\n",
    "y_train = train['sentiment'].values\n",
    "X_test = test['review'].values\n",
    "y_test = test['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVING NON-WORD CHARACTERS FROM THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, pattern):\n",
    "    if pattern=='[.]+':\n",
    "        text = re.sub(pattern, '. ', text)\n",
    "    elif pattern ==\"[']\":\n",
    "        text =  re.sub(pattern, ' ', text)\n",
    "    else:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    #print(text, '\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '<[^>]*>') #remove markup\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '<[^>]*>') #remove markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[.]+') #remove ... and replace with .\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[.]+') #remove ... and replace with ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[0-9]+') #remove numbers and replace with none\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[0-9]+') #remove numbers and replace with none\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, \"[']\") #remove ' and replace with \n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#train.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, \"[']\") #remove ' and replace with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[^\\w\\s]*') #remove everything that's not word space\n",
    "# ' is left to handle contractions\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "X_test = np.vectorize(preprocess)(X_test, '[^\\w\\s]*') #remove everything that's not word space or '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is about a group of people who are infected by a powerful manmade virus  They are pursued by government men into the desert The premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  At no point does the film engage with the viewer on any level  Granted the miniscule budget is a problem but is not the reason for the film s failure  Much more at fault is the very pofaced delivery  There is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  Very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  A much better title for this film would have been Four People Run About In The Desert With Some Stock Footage Of A Helicopter  Overall very tedious '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie is about a group of people who are infected by a powerful manmade virus  they are pursued by government men into the desert the premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  at no point does the film engage with the viewer on any level  granted the miniscule budget is a problem but is not the reason for the film s failure  much more at fault is the very pofaced delivery  there is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  a much better title for this film would have been four people run about in the desert with some stock footage of a helicopter  overall very tedious \n"
     ]
    }
   ],
   "source": [
    "X_train = [sentence.lower() for sentence in X_train] #make it lower\n",
    "print(X_train[0])\n",
    "X_test = [sentence.lower() for sentence in X_test] #make it lower\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#X_test = X_test.str.lower()#make it lower\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOES IT MAKE SENSE TO REMOVE SOME WORDS TO REDUCE COMPUTATION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121963"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(X_train)\n",
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got over 2 Lakh words --> it makes sense to remove some words like articles and prepositions out\n",
    "#### Better to remove stop words first (Why? --> documentation wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#something with tfidf\n",
    "#question: does it make sense to do tfidf first and then remove stop words using the nltk corpus or \n",
    "#remove stop words using the corpus first then perform tfidf next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) #set makes serach O(1)\n",
    "#originally stopwords.words('english') yields a list\n",
    "#print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_stem(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    #print(text_)\n",
    "    for word in text_:\n",
    "        if word not in stop:\n",
    "            tokens.append(ps.stem(word))\n",
    "    #return lemmatization(tokens)\n",
    "    #print(tokens)\n",
    "    text = ' '.join(tokens) #send only tokens sent as a joined sentence\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(remove_stopwords_and_stem)(X_train)\n",
    "X_test = np.vectorize(remove_stopwords_and_stem)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp.download('wordnet')\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    for word in text_:\n",
    "        tokens.append(lemmatizer.lemmatize(word))\n",
    "    text = ' '.join(tokens)\n",
    "    reviews.append(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(lemmatization)(X_train)\n",
    "X_test = np.vectorize(lemmatization)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/2387632182.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_reviews = np.array(reviews)\n"
     ]
    }
   ],
   "source": [
    "all_reviews = np.array(reviews)\n",
    "del reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:48:33,397 : INFO : collecting all words and their counts\n",
      "2021-10-04 20:48:33,397 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-04 20:48:33,576 : INFO : PROGRESS: at sentence #10000, processed 1160527 words, keeping 46426 word types\n",
      "2021-10-04 20:48:33,762 : INFO : PROGRESS: at sentence #20000, processed 2337204 words, keeping 68209 word types\n",
      "2021-10-04 20:48:33,950 : INFO : PROGRESS: at sentence #30000, processed 3510222 words, keeping 86075 word types\n",
      "2021-10-04 20:48:34,142 : INFO : PROGRESS: at sentence #40000, processed 4660315 words, keeping 102157 word types\n",
      "2021-10-04 20:48:34,318 : INFO : collected 116586 word types from a corpus of 5783944 raw words and 49584 sentences\n",
      "2021-10-04 20:48:34,318 : INFO : Loading a fresh vocabulary\n",
      "2021-10-04 20:48:34,477 : INFO : effective_min_count=1 retains 116586 unique words (100% of original 116586, drops 0)\n",
      "2021-10-04 20:48:34,478 : INFO : effective_min_count=1 leaves 5783944 word corpus (100% of original 5783944, drops 0)\n",
      "2021-10-04 20:48:34,748 : INFO : deleting the raw counts dictionary of 116586 items\n",
      "2021-10-04 20:48:34,751 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2021-10-04 20:48:34,752 : INFO : downsampling leaves estimated 5463839 word corpus (94.5% of prior 5783944)\n",
      "2021-10-04 20:48:34,987 : INFO : estimated required memory for 116586 words and 256 dimensions: 297061128 bytes\n",
      "2021-10-04 20:48:34,987 : INFO : resetting layer weights\n",
      "2021-10-04 20:48:51,694 : INFO : training model with 5 workers on 116586 vocabulary and 256 features, using sg=2 hs=0 sample=0.001 negative=5 window=3\n",
      "2021-10-04 20:48:52,726 : INFO : EPOCH 1 - PROGRESS: at 10.14% examples, 537900 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:53,735 : INFO : EPOCH 1 - PROGRESS: at 20.81% examples, 555663 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:54,737 : INFO : EPOCH 1 - PROGRESS: at 30.96% examples, 556865 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:55,741 : INFO : EPOCH 1 - PROGRESS: at 41.22% examples, 557659 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:56,744 : INFO : EPOCH 1 - PROGRESS: at 51.52% examples, 560098 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:57,747 : INFO : EPOCH 1 - PROGRESS: at 61.63% examples, 558424 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:58,752 : INFO : EPOCH 1 - PROGRESS: at 72.45% examples, 561033 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:48:59,755 : INFO : EPOCH 1 - PROGRESS: at 82.80% examples, 560996 words/s, in_qsize 10, out_qsize 0\n",
      "2021-10-04 20:49:00,760 : INFO : EPOCH 1 - PROGRESS: at 93.00% examples, 560798 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:01,357 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 20:49:01,358 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 20:49:01,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 20:49:01,413 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 20:49:01,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 20:49:01,414 : INFO : EPOCH - 1 : training on 5783944 raw words (5463501 effective words) took 9.7s, 562376 effective words/s\n",
      "2021-10-04 20:49:02,450 : INFO : EPOCH 2 - PROGRESS: at 9.79% examples, 516181 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:03,460 : INFO : EPOCH 2 - PROGRESS: at 20.12% examples, 535566 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:04,507 : INFO : EPOCH 2 - PROGRESS: at 30.48% examples, 538384 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:05,530 : INFO : EPOCH 2 - PROGRESS: at 39.66% examples, 527609 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:06,542 : INFO : EPOCH 2 - PROGRESS: at 48.52% examples, 518273 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:07,572 : INFO : EPOCH 2 - PROGRESS: at 58.27% examples, 518434 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:08,577 : INFO : EPOCH 2 - PROGRESS: at 68.62% examples, 523995 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:09,588 : INFO : EPOCH 2 - PROGRESS: at 78.06% examples, 521009 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:10,602 : INFO : EPOCH 2 - PROGRESS: at 87.07% examples, 517611 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:11,651 : INFO : EPOCH 2 - PROGRESS: at 94.22% examples, 503060 words/s, in_qsize 10, out_qsize 0\n",
      "2021-10-04 20:49:12,720 : INFO : EPOCH 2 - PROGRESS: at 98.81% examples, 477772 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-04 20:49:12,744 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 20:49:12,782 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 20:49:12,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 20:49:12,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 20:49:12,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 20:49:12,854 : INFO : EPOCH - 2 : training on 5783944 raw words (5464022 effective words) took 11.4s, 477801 effective words/s\n",
      "2021-10-04 20:49:13,864 : INFO : EPOCH 3 - PROGRESS: at 5.42% examples, 288742 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:14,871 : INFO : EPOCH 3 - PROGRESS: at 12.19% examples, 329900 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:15,875 : INFO : EPOCH 3 - PROGRESS: at 20.27% examples, 365709 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:16,894 : INFO : EPOCH 3 - PROGRESS: at 28.98% examples, 391427 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:17,914 : INFO : EPOCH 3 - PROGRESS: at 36.97% examples, 399350 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:18,963 : INFO : EPOCH 3 - PROGRESS: at 46.99% examples, 421189 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:19,966 : INFO : EPOCH 3 - PROGRESS: at 57.26% examples, 440839 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:21,013 : INFO : EPOCH 3 - PROGRESS: at 67.04% examples, 449599 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:22,019 : INFO : EPOCH 3 - PROGRESS: at 76.65% examples, 456445 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:23,045 : INFO : EPOCH 3 - PROGRESS: at 86.24% examples, 462004 words/s, in_qsize 10, out_qsize 0\n",
      "2021-10-04 20:49:24,084 : INFO : EPOCH 3 - PROGRESS: at 96.01% examples, 466796 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:24,437 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 20:49:24,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 20:49:24,454 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 20:49:24,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 20:49:24,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 20:49:24,481 : INFO : EPOCH - 3 : training on 5783944 raw words (5463575 effective words) took 11.6s, 470064 effective words/s\n",
      "2021-10-04 20:49:25,516 : INFO : EPOCH 4 - PROGRESS: at 9.79% examples, 516695 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:26,520 : INFO : EPOCH 4 - PROGRESS: at 18.09% examples, 482203 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:27,520 : INFO : EPOCH 4 - PROGRESS: at 27.70% examples, 495565 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:28,540 : INFO : EPOCH 4 - PROGRESS: at 38.68% examples, 520916 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:29,552 : INFO : EPOCH 4 - PROGRESS: at 49.71% examples, 537062 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:30,552 : INFO : EPOCH 4 - PROGRESS: at 56.74% examples, 511781 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:31,568 : INFO : EPOCH 4 - PROGRESS: at 63.34% examples, 489876 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:32,582 : INFO : EPOCH 4 - PROGRESS: at 71.96% examples, 485125 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:33,592 : INFO : EPOCH 4 - PROGRESS: at 79.95% examples, 478630 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:34,596 : INFO : EPOCH 4 - PROGRESS: at 89.49% examples, 483028 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:35,601 : INFO : EPOCH 4 - PROGRESS: at 98.32% examples, 483183 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:35,732 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:49:35,761 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 20:49:35,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 20:49:35,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 20:49:35,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 20:49:35,793 : INFO : EPOCH - 4 : training on 5783944 raw words (5463404 effective words) took 11.3s, 483087 effective words/s\n",
      "2021-10-04 20:49:36,801 : INFO : EPOCH 5 - PROGRESS: at 8.77% examples, 475410 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:37,828 : INFO : EPOCH 5 - PROGRESS: at 19.42% examples, 520102 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:38,834 : INFO : EPOCH 5 - PROGRESS: at 29.81% examples, 535514 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:39,835 : INFO : EPOCH 5 - PROGRESS: at 39.82% examples, 539607 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:40,854 : INFO : EPOCH 5 - PROGRESS: at 50.03% examples, 542103 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:41,859 : INFO : EPOCH 5 - PROGRESS: at 60.43% examples, 546331 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:42,871 : INFO : EPOCH 5 - PROGRESS: at 70.88% examples, 547527 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:43,892 : INFO : EPOCH 5 - PROGRESS: at 81.42% examples, 549039 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:44,921 : INFO : EPOCH 5 - PROGRESS: at 92.02% examples, 550821 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 20:49:45,600 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 20:49:45,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 20:49:45,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 20:49:45,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 20:49:45,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 20:49:45,673 : INFO : EPOCH - 5 : training on 5783944 raw words (5463844 effective words) took 9.9s, 553218 effective words/s\n",
      "2021-10-04 20:49:45,674 : INFO : training on a 28919720 raw words (27318346 effective words) took 54.0s, 506086 effective words/s\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(all_reviews, window = 3, min_count = 1, sg = 2, size = 256, workers = 5) #sg --> skipgram\n",
    "#workers --> number of threads in useb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:49:45,686 : INFO : storing 116586x256 projection weights into ../word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "#need to save model here\n",
    "word2vec_model.wv.save_word2vec_format('../word_embeddings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:50:03,374 : INFO : loading projection weights from ../word_embeddings.txt\n",
      "2021-10-04 20:50:18,493 : INFO : loaded (116586, 256) matrix from ../word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('../word_embeddings.txt', binary = False, unicode_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/2249627907.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec_model.wv.similarity('saw', 'may')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4202183"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.similarity('saw', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/2398758838.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec_model.wv.similarity('saw', 'say')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4640008"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.similarity('saw', 'say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/614821656.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec_model.wv.similarity('say', 'may')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43606555"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.similarity('say', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/824283604.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec_model.wv.similarity('gangsta', 'latino')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7215072"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.similarity('gangsta', 'latino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\AppData\\Local\\Temp/ipykernel_20352/2160411253.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  len(word2vec_model.wv.vocab)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116586"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load dictionary of word to vectors --> from gensim instance to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "with open('../word_embeddings.txt', encoding = 'utf-8') as f:\n",
    "    #page = f.read()\n",
    "    for line in f:\n",
    "        record = line.split()\n",
    "        #print(record[0])\n",
    "        #word = record[0]\n",
    "        embedding[record[0]] = np.asarray(record[1:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116587\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = Tokenizer()\n",
    "token_tensor.fit_on_texts(all_reviews)\n",
    "maxim = 0\n",
    "for  review in all_reviews:\n",
    "    maxim = max(maxim, len(review))\n",
    "X_train_token = token_tensor.texts_to_sequences(all_reviews)\n",
    "X_train_pad = pad_sequences(X_train_token, maxlen = maxim, padding='post')\n",
    "X_test_token = token_tensor.texts_to_sequences(all_reviews)\n",
    "X_test_pad = pad_sequences(X_train_token, maxlen = maxim, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
